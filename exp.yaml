# Dataset & Log
# dataset_path: "./home/dev/public-datasets/e.shvetsov/PIM/FOR_COOPERATION/rx_filter.mat"  # Data path
dataset_path: ../../../Data/FOR_COOPERATION/  # Data path
dataset_name: "1TR_C20Nc1CD_E20Ne1CD_20250117_5m"  # Dataset names
log_our_dir:  "./results"  # Filename to save model and log to
log_precision: 8  # Number of decimals in the log files
# filter_path: "/home/dev/public-datasets/e.shvetsov/PIM/FOR_COOPERATION/rx_filter.mat"
filter_path: ../../../Data/FOR_COOPERATION/rx_filter.mat


PIM_backbone: "linear"  # Modeling PIM Recurrent layer type (choices: ["gmp", "fcn", "gru", "dgru", "qgru", "qgru_amp1", "lstm", "vdlstm", "rvtdcnn", "dgru_abs_only", "linear"])
PIM_hidden_size: 8  # Hidden size of PIM backbone
PIM_num_layers: 1  # Number of layers of the PIM backbone

# Training Process
step: "train_pim"  # Step to run
# n_back: 4  # Number of backward steps
# n_fwd: 3  # Number of forward steps
n_back: 28  # Number of backward steps
n_fwd: 1  # Number of forward steps
eval_val: 1  # Whether evaluate val set during training
eval_test: 1  # Whether evaluate test set during training
# accelerator: "cuda"  # Accelerator types (choices: ["cpu", "cuda", "mps"])
accelerator: "cpu"  # Accelerator types (choices: ["cpu", "cuda", "mps"])
devices: 0  # Which accelerator to train on
re_level: "soft"  # Level of reproducibility (choices: ["soft", "hard"])

# General Hyperparameters
seed: 0  # Global random number seed
loss_type: "l2"  # Type of loss function (choices: ["l1", "l2"])
opt_type: "adamw"  # Type of optimizer (choices: ["sgd", "adam", "adamw", "adabound", "rmsprop"])
batch_size: 32  # Batch size for training
batch_size_eval: 256  # Batch size for evaluation
n_epochs: 1  # Number of epochs to train for
# n_epochs: 100  # Number of epochs to train for
lr_schedule: 1  # Whether enable learning rate scheduling
lr: 1e-4  # Learning rate
lr_end: 1e-6  # Learning rate
decay_factor: 0.5  # Learning rate decay factor
patience: 10.0  # Patience for learning rate scheduling
grad_clip_val: 200.0  # Gradient clipping value
train_ratio: 0.6
val_ratio: 0.2
test_ratio: 0.2

# GMP Hyperparameters
K: 4  # Degree of GMP model